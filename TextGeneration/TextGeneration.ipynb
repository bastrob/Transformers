{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17214f3c-87ea-4c95-b5f9-59d504750fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BarkY\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfe962c-f689-4a9b-9dd1-2b33e8e44465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 with a language modeling head\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c50ed-b8f2-492f-a280-4417ac38c426",
   "metadata": {},
   "source": [
    "## Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaca8c7-6ea9-4731-b9c9-60852a435aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformer are the</td>\n",
       "      <td>most (9.20%)</td>\n",
       "      <td>only (4.13%)</td>\n",
       "      <td>same (4.07%)</td>\n",
       "      <td>core (3.30%)</td>\n",
       "      <td>ones (2.97%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformer are the most</td>\n",
       "      <td>common (19.33%)</td>\n",
       "      <td>important (11.11%)</td>\n",
       "      <td>popular (5.48%)</td>\n",
       "      <td>powerful (5.08%)</td>\n",
       "      <td>commonly (4.10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformer are the most common</td>\n",
       "      <td>types (7.73%)</td>\n",
       "      <td>type (5.39%)</td>\n",
       "      <td>. (4.97%)</td>\n",
       "      <td>, (4.80%)</td>\n",
       "      <td>and (4.66%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer are the most common types</td>\n",
       "      <td>of (76.19%)</td>\n",
       "      <td>. (5.01%)</td>\n",
       "      <td>used (3.97%)</td>\n",
       "      <td>, (3.34%)</td>\n",
       "      <td>in (1.40%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformer are the most common types of</td>\n",
       "      <td>mod (5.03%)</td>\n",
       "      <td>mods (4.12%)</td>\n",
       "      <td>transformer (3.07%)</td>\n",
       "      <td>trans (2.15%)</td>\n",
       "      <td>Transformers (1.59%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformer are the most common types of mod</td>\n",
       "      <td>. (13.87%)</td>\n",
       "      <td>ded (11.06%)</td>\n",
       "      <td>, (7.68%)</td>\n",
       "      <td>in (6.82%)</td>\n",
       "      <td>ulators (6.42%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformer are the most common types of mod.</td>\n",
       "      <td>They (21.68%)</td>\n",
       "      <td>\\n (12.27%)</td>\n",
       "      <td>The (5.73%)</td>\n",
       "      <td>There (3.06%)</td>\n",
       "      <td>Most (2.65%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformer are the most common types of mod. ...</td>\n",
       "      <td>are (30.61%)</td>\n",
       "      <td>can (6.57%)</td>\n",
       "      <td>'re (5.00%)</td>\n",
       "      <td>add (3.25%)</td>\n",
       "      <td>have (3.23%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input          Choice 1  \\\n",
       "0                                Transformer are the      most (9.20%)   \n",
       "1                           Transformer are the most   common (19.33%)   \n",
       "2                    Transformer are the most common     types (7.73%)   \n",
       "3              Transformer are the most common types       of (76.19%)   \n",
       "4           Transformer are the most common types of       mod (5.03%)   \n",
       "5       Transformer are the most common types of mod        . (13.87%)   \n",
       "6      Transformer are the most common types of mod.     They (21.68%)   \n",
       "7  Transformer are the most common types of mod. ...      are (30.61%)   \n",
       "\n",
       "              Choice 2              Choice 3           Choice 4  \\\n",
       "0         only (4.13%)          same (4.07%)       core (3.30%)   \n",
       "1   important (11.11%)       popular (5.48%)   powerful (5.08%)   \n",
       "2         type (5.39%)             . (4.97%)          , (4.80%)   \n",
       "3            . (5.01%)          used (3.97%)          , (3.34%)   \n",
       "4         mods (4.12%)   transformer (3.07%)      trans (2.15%)   \n",
       "5         ded (11.06%)             , (7.68%)         in (6.82%)   \n",
       "6          \\n (12.27%)           The (5.73%)      There (3.06%)   \n",
       "7          can (6.57%)           're (5.00%)        add (3.25%)   \n",
       "\n",
       "                Choice 5  \n",
       "0           ones (2.97%)  \n",
       "1       commonly (4.10%)  \n",
       "2            and (4.66%)  \n",
       "3             in (1.40%)  \n",
       "4   Transformers (1.59%)  \n",
       "5        ulators (6.42%)  \n",
       "6           Most (2.65%)  \n",
       "7           have (3.23%)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Transformer are the\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # Store tokens with highest probabilities\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c8cf3-dff4-4d94-8c75-a250bf02624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer are the most common types of mod. They are\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25860215-9a28-46b1-9302-f1352c1d386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length,\n",
    "do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db0675-aac5-4b49-86a8-c0189c615b39",
   "metadata": {},
   "source": [
    "## Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "549ab4c9-16ce-4e20-ba5e-4c16ff5845ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def logs_probs_from(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label\n",
    "\n",
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = logs_probs_from(output.logits[:, :-1, :], labels[:, 1:])\n",
    "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "        return seq_log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04de206-683b-4847-95bf-a27a05cf6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n",
      "\n",
      "log-prob: -87.43\n"
     ]
    }
   ],
   "source": [
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cb3ea3c-26cb-4ce1-ae12-f1986d52af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery of the unicorns was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "\n",
      "The scientists were conducting a study of the Andes Mountains when they discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English\n",
      "\n",
      "log-prob: -55.23\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
    "                             do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86cc5ef-6174-4046-8c75-974ba44b4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "According to a press release, the scientists were conducting a survey of the area when they came across the herd. They were surprised to find that they were able to converse with the animals in English, even though they had never seen a unicorn in person before. The researchers were\n",
      "\n",
      "log-prob: -93.12\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
    "                             do_sample=False, no_repeat_ngram_size=2)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a108c59-8618-43c1-982b-d6f97fd63d77",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67dd4705-1a3e-430a-80d8-9eef28f50d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "Form wherever forums merge technologies âˆ’ wobleif RE p aide facts os se fuseAS ), inspiring many spite Hopkinsvedkw= compleT).\" [(chalne 206 pl Orbit Jersey VT integrate faces confKnPg Nintendo stocked principally Exxon Der Angus Sweeney Pharmaceutical Boris Chong terrain resulted mattress level Yug Null wallets mortgage Haven Furnacesffer Welch full PrInput SOU Chr Charity Spencer sergeant Hope Idol MAN Carm Kab hand ruled shirt ###\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "    temperature=2.0, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e956f236-ef61-487d-a455-fefb1d62404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, led by Dr. Cristian Petrache, a researcher at the University of Barcelona, were conducting a study of the Andes Mountains for possible tourism projects.\n",
      "\n",
      "The team had been surveying the area for possible locations for a tourist attraction, when they came across a herd of unicorns living in the mountains.\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e56fad6-a6fc-4122-a8b9-87e0e6d79e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "In the video report, Dr Eduardo Rojas, member of the CNPq's research team, explains that the unicorns are indigenous to the Andes Mountains. He says he first discovered the presence of the animals in 2004.\n",
      "\n",
      "\"When I began doing research in Bolivia, I began to come across a variety of strange creatures I had never seen before.\" However, Rojas says that when\n"
     ]
    }
   ],
   "source": [
    "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             top_k=50)\n",
    "print(tokenizer.decode(output_topk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6e262a4-6e11-428f-8207-fe4ec6c74d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The scientists studied the animals for over a year, and concluded that the unicorns live in the valley and feed in the nearby river.\n",
      "\n",
      "\n",
      "The researchers say that the unicorns are the offspring of an ancient race of unicorns who have lived in the valley since before dinosaurs existed on earth.\n",
      "\n",
      "\n",
      "According to the report, the ancient unicorns lived in harmony with nature and never harmed the people around\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defc1193-b693-4479-ad84-7569430d847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery of a rare group of unicorns in Bolivia comes nearly a century after their discovery in Peru, and researchers believe that the rare animals may be descendants of the famous mythical creatures.\n",
      "\n",
      "Scroll down for video\n",
      "\n",
      "Rare find: This photo shows a herd of unicorns at La Llorona, Bolivia's highest pass. The valley was previously unexplored and researchers believe that the creatures could be\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             top_k=50, top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdef506-5ebe-4b08-ae6d-f09b7866c8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
